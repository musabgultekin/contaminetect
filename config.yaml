debug: True
output_dir: output

embedding:
  # model: hkunlp/instructor-large
  # model: all-mpnet-base-v2
  # model: sentence-transformers/all-MiniLM-L6-v2 # 23M param
  model: nomic-ai/nomic-embed-text-v1 #Â 137M param
  cache_dir: cache
  batch_size: 128
  max_seq_length: 512
  # batch_size: 8
  # max_seq_length: 8192
  similarity_threshold: 0.9
  # prompt: "Represent the prompt for duplicate detection"

training_datasets:
  - args:
      path: teknium/OpenHermes-2.5
      split: train
    prompt_jmespath: "conversations[0].value"
  # - args:
  #     path: deepmind/aqua_rat
  #     name: raw
  #     split: train
  #   prompt_jmespath: question
  # - args:
  #     path: cognitivecomputations/boolq_sharegpt
  #     split: train
  #   prompt_jmespath: "conversations[0].value"

evaluation_datasets:
  - args:
      path: openai/gsm8k
      name: main
      split: test
    prompt_jmespath: question
  - args:
      path: allenai/ai2_arc
      name: ARC-Challenge
      split: test
    prompt_jmespath: question
  - args:
      path: HuggingFaceH4/mt_bench_prompts
      split: train
    prompt_jmespath: "prompt[0]"
  - args:
      path: cais/mmlu
      name: all
      split: dev
    prompt_jmespath: question
  - args:
      path: alvarobartt/lmsys-arena-hard-v0.1
      split: test
    prompt_jmespath: "turns[0].content"
